* http://qz.com/857122/an-algorithm-rejected-an-asian-mans-passport-photo-for-having-closed-eyes/

A man’s passport photo was rejected by facial recognition software because it
didn’t find his eyes to be open—this man was Asian.

* http://www.nytimes.com/roomfordebate/2015/11/18/can-predictive-policing-be-ethical-and-effective

Collection of NYTimes debate columns over data-driven policing.

* https://backchannel.com/put-away-your-machine-learning-hammer-criminality-is-not-a-nail-1309c84bb899#.kl1vgdh1s

Discussion of the bias inherent in training data—even if an algorithm is
”objective”, the data we train it with is biased from the existing systemic
bias of the system.
