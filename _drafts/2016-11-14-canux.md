An interesting thread ran through CanUX this weekend. After a week that saw the “end” of a presidential campaign season marked by intense social media use, multiple speakers spun their talks around the algorithms that govern our lives.

Simone Rebaudengo talked about how our desire to make everything “smart” has led to us handing more and more over to “black boxes”—the algorithms that manage our smart products. The black box takes input and transforms it, through some obscure process, into socially accepted output. We implicitly trust this obscurity through our continued use of these algorithm-driven products. Even though we have no idea what’s really going on, we accept it and move on with our lives, rarely pausing to consider the hidden algorithm’s transformative influence.

Digging into this theme from another perspective was Alan Cooper. He argued for the need to stop, look around, and listen to our world. Taking up the fight against “digital industrialists”—Amazon, Google, Facebook, and the like—he noted that tech plays a larger role than we think in the world, that we have to be aware and protective of our responsibility in shaping it. To this end, he questioned the social media “everyone agrees with me” echo chamber: what service do we do society when we write algorithms to filter news feeds based on whether someone is liberal or conservative? Why should the service—or, more accurately, the algorithm—decide what we can and cannot see?

***

The U.S. election has tired me out. For months I followed along somewhat closely, to the point that my Twitter and Facebook feeds seemed to show only election content. This was handy, when I was willing to constantly engage with it! Sadly, after the election, it’s become frustrating: I can’t turn away from it all, even if I want to. I realize that I’m fortunate to have the luxury of being able to disengage; many in the U.S. are ramping up now to fight for their lives, a situation nobody should ever have to be in.

In any case, I wanted something different from my social media—I wanted to return to the design and development news that I had originally used the services to follow. Unfortunately, there wasn’t really an explicit way for me to tell the services what I wanted to be seeing more of. Even if I unfollowed journalists whose work I admire (something I don’t want to do), Twitter would still suggest their Tweets. As expected, I’d like them, and Twitter would serve me more the next time I visited. The black box was working against me.

It’s here that the significance of another part of Simone’s presentation began to grow in my mind. He talked about a project he’d done where he envisioned a new job in society: [the algorithm teacher](http://www.simonerebaudengo.com/#/teacher/). You could give this teacher your smart, algorithm-based products, and they’d be worked through a rigorous curriculum in order to develop their algorithms in well-rounded ways. I realized that the only way I could effectively work against these black boxes was to re-train their “understanding” (or, more accurately, calculation) of who I was.

***

It’s been a month and a half since I wrote those paragraphs, and I can report now on the results: I just gave up. Increasingly, I’ve checked out of social media. My reasons for this are twofold: one, the standard set, that social media is distracting, that it carves up your attention, and that it mostly just contributes to the noise of the world; two, a less heard of but not uncommon set, that social media is driven by algorithms which effectively take away much of your ability to curate your own selection of content to consider.

I found re-training the social media algorithms to be too immense of a task. There was nowhere I could adjust the sliders that determine the content served to me, nowhere I could tell the networks the real reasons I used them. Of course, this is a sensible trade-off in products: they’re designed to accomplish certain ends, and focused on doing so. They’re not going to work for every person or every use case. Social media’s great power is in obscuring that fact while contributing ever more to our addictions.

Instead of finding things to read via social media, then, I started to actively seek them out. Previously a half hour would be carved up into hundreds of tweets, my “substantial” reading consisting of quick scans over a few articles found through Twitter. Now I started to spend a half hour on a single person’s site, reading the articles that interested me and devoting my attention more fully.

While I can’t necessarily attribute it directly to my changed usage patterns of social media, things *feel* different. I’m more critical of the pieces I read, because I’m more intentional about finding them. My attention is less divided, and I’m more able to focus while reading. And, most significantly, there’s no invisible algorithm deciding what I “want” to engage with—it’s my own thought process, relatively transparent.